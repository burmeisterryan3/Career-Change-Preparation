{"cells":[{"source":"# What's in an Avocado Toast: A Supply Chain Analysis\n\nYou're in London, making an avocado toast, a quick-to-make dish that has soared in popularity on breakfast menus since the 2010s. A simple smashed avocado toast can be made with five ingredients: one ripe avocado, half a lemon, a big pinch of salt flakes, two slices of sourdough bread and a good drizzle of extra virgin olive oil. It's no small feat that most of these ingredients are readily available in grocery stores. \n\nIn this project, you'll conduct a supply chain analysis of three of these ingredients used in an avocado toast, utilizing the Open Food Facts database. This database contains extensive, openly-sourced information on various foods, including their origins. Through this analysis, you will gain an in-depth understanding of the complex supply chain involved in producing a single dish.\n\nThree pairs of files are provided in the data folder:\n- A CSV file for each ingredient, such as `avocado.csv`, with data about each food item and countries of origin\n- A TXT file for each ingredient, such as `relevant_avocado_categories`, containing only the category tags of interest for that food.\n\nHere are some other key points about these files:\n- Some of the rows of data in each of the three CSV files do not contain relevant data for your investigation. In each dataset, you will need to filter out rows with irrelevant data, based on values in the `categories_tags` column. Examples of categories are, fruits, vegetables, and fruit-based oils. Filter the DataFrame to include only rows where `categories_tags` contains one of the tags in the relevant categories for that ingredient.\n- Each row of data usually has multiple categories tags in the `categories_tags` column.\n- There is a column in each CSV file called `origins_tags` with strings for country of origin of that item.\n\nAfter completing this project, you'll be armed with a list of ingredients and their countries of origin, and be well-positioned to launch into other analyses that explore how long, on average, these ingredients spend at sea.\n\n![](avocado_wallpaper.jpeg)","metadata":{},"id":"32ec92a0-c21a-45b8-ac63-9f9c698a1291","cell_type":"markdown"},{"source":"import pandas as pd\nimport numpy as np","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1715612565114,"lastExecutedByKernel":"4ff97033-672f-407c-b747-0f604d5e6d16","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nimport numpy as np"},"id":"95870cf7-b34c-4589-b9bc-da4a45f48a09","cell_type":"code","execution_count":219,"outputs":[]},{"source":"# Set up necessary info for reading files\ncsv_delimiter = '/t'\navocado_categories_file = 'data/relevant_avocado_categories.txt' \navocado_csv = 'data/avocado.csv'\nolive_oil_categories_file = 'data/relevant_olive_oil_categories.txt' \nolive_oil_csv = 'data/olive_oil.csv'\nsourdough_categories_file = 'data/relevant_sourdough_categories.txt' \nsourdough_csv = 'data/sourdough.csv'","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1715612565163,"lastExecutedByKernel":"4ff97033-672f-407c-b747-0f604d5e6d16","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Set up necessary info for reading files\ncsv_delimiter = '/t'\navocado_categories_file = 'data/relevant_avocado_categories.txt' \navocado_csv = 'data/avocado.csv'\nolive_oil_categories_file = 'data/relevant_olive_oil_categories.txt' \nolive_oil_csv = 'data/olive_oil.csv'\nsourdough_categories_file = 'data/relevant_sourdough_categories.txt' \nsourdough_csv = 'data/sourdough.csv'"},"cell_type":"code","id":"bf2c39b0-7baa-4ef8-9742-3a6b3c09119e","outputs":[],"execution_count":220},{"source":"def get_categories(filename):\n    with open(filename) as f:\n        categories = [line.rstrip() for line in f]\n\n    return categories","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1715612565215,"lastExecutedByKernel":"4ff97033-672f-407c-b747-0f604d5e6d16","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def get_categories(filename):\n    with open(filename) as f:\n        categories = [line.rstrip() for line in f]\n\n    return categories","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"cell_type":"code","id":"45ce9da8-bb49-4d3a-a1f1-8877e593b1b2","outputs":[],"execution_count":221},{"source":"def get_ingredient_df(filename):\n    df = pd.read_csv(filename, delimiter='\\t', usecols=['categories_tags', 'origins_tags', 'countries'])\n    df.dropna(inplace=True)\n    df = df[df['countries'] == 'United Kingdom']\n    return df","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1715612565267,"lastExecutedByKernel":"4ff97033-672f-407c-b747-0f604d5e6d16","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def get_ingredient_df(filename):\n    df = pd.read_csv(filename, delimiter='\\t', usecols=['categories_tags', 'origins_tags', 'countries'])\n    df.dropna(inplace=True)\n    df = df[df['countries'] == 'United Kingdom']\n    return df","outputsMetadata":{"0":{"height":196,"type":"dataFrame"}}},"cell_type":"code","id":"f22c0824-8477-4016-8649-783e0eae0b02","outputs":[],"execution_count":222},{"source":"# Initial attempt using regex on string in column\ndef get_filtered_df_1(df, categories):\n    # Initialize an empty DataFrame to store the filtered results\n    filtered_df = pd.DataFrame()\n\n    # Iterate over each search string and apply the search individually\n    for serach_string in categories:\n        # Use str.contains() with a regular expression to search within the 'categories_tags' column\n        # The regular expression ensures that the search is performed on text separated by commas\n        # Case sensitivity can be controlled using the 'case' parameter\n        temp_df = df[df['categories_tags'].str.contains(r'[^,]+'.format(search_string), case=False)]\n\n        # Append the filtered results to the main DataFrame\n        filtered_df = filtered_df.append(temp_df)\n\n    filtered_df = filtered_df.drop_duplicates()\n    \n    # Split the strings in the 'origins_tags' column by commas\n    filtered_df['origins_tags'] = filtered_df['origins_tags'].str.split(',')\n    \n    # Explode the lists in the 'origins_tags' column into separate rows\n    filtered_df = filtered_df.explode('origins_tags')\n    \n    return filtered_df","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1715612660254,"lastExecutedByKernel":"4ff97033-672f-407c-b747-0f604d5e6d16","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initial attempt using regex on string in column\ndef get_filtered_df_1(df, categories):\n    # Initialize an empty DataFrame to store the filtered results\n    filtered_df = pd.DataFrame()\n\n    # Iterate over each search string and apply the search individually\n    for serach_string in categories:\n        # Use str.contains() with a regular expression to search within the 'categories_tags' column\n        # The regular expression ensures that the search is performed on text separated by commas\n        # Case sensitivity can be controlled using the 'case' parameter\n        temp_df = df[df['categories_tags'].str.contains(r'[^,]+'.format(search_string), case=False)]\n\n        # Append the filtered results to the main DataFrame\n        filtered_df = filtered_df.append(temp_df)\n\n    filtered_df = filtered_df.drop_duplicates()\n    \n    # Split the strings in the 'origins_tags' column by commas\n    filtered_df['origins_tags'] = filtered_df['origins_tags'].str.split(',')\n    \n    # Explode the lists in the 'origins_tags' column into separate rows\n    filtered_df = filtered_df.explode('origins_tags')\n    \n    return filtered_df"},"cell_type":"code","id":"89d1d3f0-9f88-4aef-9cb7-2aff27dd3193","outputs":[],"execution_count":234},{"source":"# Second attempt splitting string on delimiter into new column\ndef get_filtered_df_2(df, categories):\n    df['categories_list'] = df['categories_tags'].str.split(',')\n    df = df[df['categories_list']\\\n            .apply(lambda row: any([category for category in row if category in categories]))]\n    df['origins_tags'] = df['origins_tags'].str.split(',')\n    \n    # Explode the lists in the 'origins_tags' column into separate rows\n    df = df.explode('origins_tags')\n      \n    return df","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1715612659191,"lastExecutedByKernel":"4ff97033-672f-407c-b747-0f604d5e6d16","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Second attempt splitting string on delimiter into new column\ndef get_filtered_df_2(df, categories):\n    df['categories_list'] = df['categories_tags'].str.split(',')\n    df = df[df['categories_list']\\\n            .apply(lambda row: any([category for category in row if category in categories]))]\n    df['origins_tags'] = df['origins_tags'].str.split(',')\n    \n    # Explode the lists in the 'origins_tags' column into separate rows\n    df = df.explode('origins_tags')\n      \n    return df"},"cell_type":"code","id":"721a8de5-3310-4b7c-bde4-c062da11847f","outputs":[],"execution_count":233},{"source":"def get_top_origin_country(categories_file, csv_file):\n    categories = get_categories(categories_file)\n    df = get_ingredient_df(csv_file)\n    # df = get_filtered_df_1(df, categories)\n    df = get_filtered_df_2(df, categories)\n\n    # Get the country which sourced the most ingredients form the initial ingredient's file\n    max_country = df['origins_tags'].value_counts().idxmax()\n    top_origin = max_country.split(':')[1].replace('-', ' ').upper()\n\n    return top_origin","metadata":{"executionCancelledAt":null,"executionTime":10,"lastExecutedAt":1715612661856,"lastExecutedByKernel":"4ff97033-672f-407c-b747-0f604d5e6d16","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def get_top_origin_country(categories_file, csv_file):\n    categories = get_categories(categories_file)\n    df = get_ingredient_df(csv_file)\n    # df = get_filtered_df_1(df, categories)\n    df = get_filtered_df_2(df, categories)\n\n    # Get the country which sourced the most ingredients form the initial ingredient's file\n    max_country = df['origins_tags'].value_counts().idxmax()\n    top_origin = max_country.split(':')[1].replace('-', ' ').upper()\n\n    return top_origin"},"cell_type":"code","id":"979eb86b-09b3-4d3a-8eb0-be5336863019","outputs":[],"execution_count":235},{"source":"# Avocados\ntop_avocado_origin = get_top_origin_country(avocado_categories_file, avocado_csv)\nprint(top_avocado_origin)","metadata":{"executionCancelledAt":null,"executionTime":35,"lastExecutedAt":1715612662798,"lastExecutedByKernel":"4ff97033-672f-407c-b747-0f604d5e6d16","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Avocados\ntop_avocado_origin = get_top_origin_country(avocado_categories_file, avocado_csv)\nprint(top_avocado_origin)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"3cf3cfdd-cb38-48c5-ae76-91046c0eba3a","outputs":[{"output_type":"stream","name":"stdout","text":"PERU\n"}],"execution_count":236},{"source":"# Olive Oil\ntop_olive_oil_origin = get_top_origin_country(olive_oil_categories_file, olive_oil_csv)\nprint(top_olive_oil_origin)","metadata":{"executionCancelledAt":null,"executionTime":101,"lastExecutedAt":1715612664564,"lastExecutedByKernel":"4ff97033-672f-407c-b747-0f604d5e6d16","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Olive Oil\ntop_olive_oil_origin = get_top_origin_country(olive_oil_categories_file, olive_oil_csv)\nprint(top_olive_oil_origin)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"5805cd09-8572-4796-aa53-73d5a295f11e","outputs":[{"output_type":"stream","name":"stdout","text":"GREECE\n"}],"execution_count":237},{"source":"# Sourdough\ntop_sourdough_origin = get_top_origin_country(sourdough_categories_file, sourdough_csv)\nprint(top_sourdough_origin)","metadata":{"executionCancelledAt":null,"executionTime":34,"lastExecutedAt":1715612665814,"lastExecutedByKernel":"4ff97033-672f-407c-b747-0f604d5e6d16","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Sourdough\ntop_sourdough_origin = get_top_origin_country(sourdough_categories_file, sourdough_csv)\nprint(top_sourdough_origin)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"ead305cf-81b9-49ce-9263-bc4b0a79aabf","outputs":[{"output_type":"stream","name":"stdout","text":"UNITED KINGDOM\n"}],"execution_count":238}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}