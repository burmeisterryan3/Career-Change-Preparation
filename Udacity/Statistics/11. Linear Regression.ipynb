{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Linear Regression\n",
    "\n",
    "When our data is linear, we found that we can describe the correlation between two variables using Person's r and a line drawn through our data. This line can be called the *regression line* or the *line of best fit* and will help us describe our data and make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology\n",
    "\n",
    "Once a line of best fine has been determined (by finding the slope and y-intercept), we can make estimates for unseen or future values. Our dataset, $\\mathcal{D}$, consists of all the pairs of observed ($x$,$y$).\n",
    "\n",
    "With the slope, $b$, and y-intercept, $a$, determined, we can make predictions $\\hat{y}=bx+a$. For a known data point ($x$, $y$), the difference between $y$ and $\\hat{y}$ is called the *residual*.\n",
    "\n",
    "When conducting regression, $a$ and $b$ are known as *regression coefficients*. It is important to note that software packages often present the coefficients in $\\hat{y}=a+bx$ order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Line of Best Fit\n",
    "\n",
    "To compute the line of best fit, we can work to try and minimze $y-\\hat{y}$ for all $(x, y) \\in\\mathcal{D}$.\n",
    "\n",
    "##### Minimize Sum of Residuals\n",
    "\n",
    "One way we could think about doing this is by summing the residuals $\\sum\\limits_{(x,y)\\in\\mathcal{D}}(y-\\hat{y})$. However, we will find that we can have poor lines of fit in this case in the even positive and negative values cancel each other out.\n",
    "\n",
    "For this reason, we usually employ an alternative method that either squares the residual or takes the absolute value before summing.\n",
    "\n",
    "##### L1, Minimize Sum of Absolute Residuals\n",
    "To overcome the cancellation of positive and negative values, we can consider summing the absolute value of the difference, $\\sum\\limits_{(x,y)\\in\\mathcal{D}}\\lvert y-\\hat{y}\\rvert$. This is an option, but we will look to the sum of squared residuals for this course.\n",
    "\n",
    "\n",
    "##### L2, Minimize Sum of Squared Residual\n",
    "\n",
    "Another way to overcome the cancellation of positive and negative values is to square the residuals. Thus, our objective is to minimize this sum of the square of the residuals. $$\\sum(y-\\hat{y})^2$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
